{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Harris 코너 검출 함수\n",
    "def corner_harris():\n",
    "    # 이미지를 그레이스케일로 로드\n",
    "    src = cv2.imread('../data/img/aaa.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 이미지 로드에 실패한 경우\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    # Harris 코너 검출 수행\n",
    "    harris = cv2.cornerHarris(src, 3, 3, 0.04)\n",
    "    # 검출된 결과를 0-255 범위로 정규화\n",
    "    harris_norm = cv2.normalize(harris, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "    # 결과를 표시하기 위해 그레이스케일 이미지를 BGR로 변환\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Harris 코너 검출 결과에서 코너점 찾기\n",
    "    for y in range(harris_norm.shape[0]):\n",
    "        for x in range(harris_norm.shape[1]):\n",
    "            # 코너 강도가 임계값(50)보다 큰 경우\n",
    "            if harris_norm[y, x] > 50:\n",
    "                # 해당 점이 주변 점들보다 강도가 큰지 확인하여 코너점인지 판단\n",
    "                if (harris[y, x] > harris[y-1, x] and\n",
    "                    harris[y, x] > harris[y-1, x] and\n",
    "                    harris[y, x] > harris[y-1, x] and\n",
    "                    harris[y, x] > harris[y-1, x]):\n",
    "                    # 코너점을 빨간 원으로 표시\n",
    "                    cv2.circle(dst, (x, y), 5, (0, 0, 255), 2)\n",
    "\n",
    "    # 원본 이미지, 정규화된 Harris 결과, 코너점이 표시된 이미지를 화면에 표시\n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('harris_norm', harris_norm)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# FAST 코너 검출 함수\n",
    "def corner_fast():\n",
    "    # 이미지를 그레이스케일로 로드\n",
    "    src = cv2.imread('../data/img/eee.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 이미지 로드에 실패한 경우\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    # FAST 검출기를 생성하고 임계값을 60으로 설정\n",
    "    fast = cv2.FastFeatureDetector_create(60)\n",
    "    # FAST 검출기를 사용하여 키포인트를 검출\n",
    "    keypoints = fast.detect(src)\n",
    "\n",
    "    # 결과를 표시하기 위해 그레이스케일 이미지를 BGR로 변환\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 검출된 키포인트마다 빨간 원으로 표시\n",
    "    for kp in keypoints:\n",
    "        pt = (int(kp.pt[0]), int(kp.pt[1]))\n",
    "        cv2.circle(dst, pt, 5, (0, 0, 255), 2)\n",
    "\n",
    "    # 원본 이미지와 코너점이 표시된 이미지를 화면에 표시\n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 메인 함수\n",
    "if __name__ == \"__main__\":\n",
    "    # Harris 코너 검출 함수 호출\n",
    "    corner_harris()\n",
    "    # FAST 코너 검출 함수 호출\n",
    "    corner_fast()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image load failed!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\cv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 입력 이미지 파일을 그레이스케일로 읽어옵니다.\n",
    "src = cv2.imread('../data/img/malle_girl.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 이미지를 읽어오는 데 실패했을 경우 에러 메시지를 출력하고 프로그램을 종료합니다.\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# ORB 검출기 객체를 생성합니다.\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# ORB를 사용하여 특징점을 검출합니다.\n",
    "keypoints = orb.detect(src)\n",
    "\n",
    "# 검출된 특징점들에 대해 기술자(Descriptor)를 계산합니다.\n",
    "keypoints, desc = orb.compute(src, keypoints)\n",
    "\n",
    "# 검출된 특징점의 개수를 출력합니다.\n",
    "print('len(keypoints):', len(keypoints))\n",
    "\n",
    "# 계산된 기술자의 크기(차원)를 출력합니다.\n",
    "print('desc.shape:', desc.shape)\n",
    "\n",
    "# 검출된 특징점을 원본 이미지 위에 그립니다. \n",
    "# cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS 플래그는 키포인트의 크기와 방향을 나타내는 원을 그리도록 합니다.\n",
    "dst = cv2.drawKeypoints(src, keypoints, None, (-1, -1, -1),\n",
    "                       cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# 원본 이미지를 화면에 출력합니다.\n",
    "cv2.imshow('src', src)\n",
    "\n",
    "# 특징점이 그려진 이미지를 화면에 출력합니다.\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "# 키 입력을 대기하고, 아무 키나 누르면 창을 닫습니다.\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc1.shape: (123, 32)\n",
      "desc2.shape: (500, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def keypoint_matching():\n",
    "    src1 = cv2.imread('../data/img/cropped.png', cv2.IMREAD_GRAYSCALE)\n",
    "    src2 = cv2.imread('../data/img/bbb.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if src1 is None or src2 is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    keypoints1, desc1 = orb.detectAndCompute(src1, None)\n",
    "    keypoints2, desc2 = orb.detectAndCompute(src2, None)\n",
    "    print('desc1.shape:', desc1.shape)\n",
    "    print('desc2.shape:', desc2.shape)\n",
    "\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    dst = cv2.drawMatches(src1, keypoints1, src2, keypoints2, matches, None)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def good_matching():\n",
    "    src1 = cv2.imread('../data/img/cropped.png', cv2.IMREAD_GRAYSCALE)\n",
    "    src2 = cv2.imread('../data/img/bbb.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if src1 is None or src2 is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    keypoints1, desc1 = orb.detectAndCompute(src1, None)\n",
    "    keypoints2, desc2 = orb.detectAndCompute(src2, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = matches[:50]\n",
    "\n",
    "    dst = cv2.drawMatches(src1, keypoints1, src2, keypoints2, good_matches, None,\n",
    "                         flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def find_homography():\n",
    "    src1 = cv2.imread('../data/img/cropped.png', cv2.IMREAD_GRAYSCALE)\n",
    "    src2 = cv2.imread('../data/img/bbb.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if src1 is None or src2 is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    keypoints1, desc1 = orb.detectAndCompute(src1, None)\n",
    "    keypoints2, desc2 = orb.detectAndCompute(src2, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = matches[:50]\n",
    "\n",
    "    dst = cv2.drawMatches(src1, keypoints1, src2, keypoints2, good_matches, None,\n",
    "                         flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    pts1 = np.array([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = np.array([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "\n",
    "    (h, w) = src1.shape[:2]\n",
    "    corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2).astype(np.float32)\n",
    "    corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "    corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "    cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    keypoint_matching()\n",
    "    good_matching()\n",
    "    find_homography()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
