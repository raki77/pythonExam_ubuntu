{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8429e352",
   "metadata": {},
   "source": [
    "## 20장 전이 학습을 통해 딥러닝의 성능 극대화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e95bb",
   "metadata": {},
   "source": [
    "### 1. 소규모 데이터셋으로 만드는 강력한 학습 모델\n",
    "#### 실습: 치매 환자의 뇌인지 일반인의 뇌인지 예측하기\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8f72b58e",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6d63524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af03afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47a98eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(\n",
    "    # 주어진 이미지의 크기를 설정합니다.\n",
    "    rescale=1./255,\n",
    "    # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "    horizontal_flip = True,\n",
    "    # 전체 크기의 15% 범위에서 좌우로 이동합니다.\n",
    "    width_shift_range=0.1,\n",
    "    # 마찬가지로 위, 아래로 이동합니다.    \n",
    "    #rotation_range=5,  # 정해진 각도만큼 회전시킵니다.\n",
    "    #shear_range=0.7,   # 좌표 하나를 고정시키고 나머지를 이동시킵니다.\n",
    "    #zoom_range=1.2,    # 확대 또는 축소시킵니다.\n",
    "    #vertical_flip=True,  # 수직 대칭 이미지를 만듭니다.\n",
    "    # 빈 공간을 채우는 방법입니다. nearest 옵션은 가장 비슷한 색으로 채우게 됩니다.\n",
    "    fill_mode='nearest'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5427d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    #  학습셋이 있는 폴더의 위치입니다.\n",
    "    '../data/train',\n",
    "    target_size = (150,150),\n",
    "    batch_size = 5,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21dee892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋은 이미지 부풀리기 과정을 진행하지 않습니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad1d9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    # 테스트셋이 있는 폴더의 위치입니다.\n",
    "    '../data/test',\n",
    "    target_size = (150,150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24f3a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00392156862745098"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. / 255 # 0과1로 사이즈 맞추는게 리스케일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce773f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150* 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8c3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 34, 34, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1183808   \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 앞서 배운 CNN 모델을 만들어 적용해 보겠습니다.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6248c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99f010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 실행의 옵션을 설정합니다. \n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizers.Adam(learning_rate=0.0002),\n",
    "            metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcd7bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습의 조기 중단을 설정합니다.\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d550117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 22ms/step - loss: 0.7248 - accuracy: 0.4938 - val_loss: 0.6939 - val_accuracy: 0.4800\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6940 - accuracy: 0.5188 - val_loss: 0.6885 - val_accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6934 - accuracy: 0.5312 - val_loss: 0.6876 - val_accuracy: 0.5800\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6768 - accuracy: 0.6250 - val_loss: 0.6709 - val_accuracy: 0.6200\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6549 - accuracy: 0.6000 - val_loss: 0.6417 - val_accuracy: 0.6200\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6178 - accuracy: 0.7063 - val_loss: 0.5753 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5900 - accuracy: 0.7125 - val_loss: 0.5884 - val_accuracy: 0.6400\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5097 - accuracy: 0.8188 - val_loss: 0.4583 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.4327 - accuracy: 0.8250 - val_loss: 0.4069 - val_accuracy: 0.8200\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.4032 - accuracy: 0.8438 - val_loss: 0.3785 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.3528 - accuracy: 0.8625 - val_loss: 0.2812 - val_accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.3393 - accuracy: 0.8562 - val_loss: 0.2887 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.2909 - accuracy: 0.8813 - val_loss: 0.2406 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.2238 - accuracy: 0.9250 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1886 - accuracy: 0.9438 - val_loss: 0.1186 - val_accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.1542 - accuracy: 0.9688 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1502 - accuracy: 0.9688 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1487 - accuracy: 0.9312 - val_loss: 0.0864 - val_accuracy: 0.9800\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1203 - accuracy: 0.9625 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1239 - accuracy: 0.9375 - val_loss: 0.1254 - val_accuracy: 0.9600\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.1326 - accuracy: 0.9688 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1428 - accuracy: 0.9375 - val_loss: 0.0954 - val_accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.1079 - accuracy: 0.9563 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1291 - accuracy: 0.9563 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9875 - val_loss: 0.0916 - val_accuracy: 0.9400\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.0402 - val_accuracy: 0.9800\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0951 - accuracy: 0.9750 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1790 - accuracy: 0.9563 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0946 - accuracy: 0.9750 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 0.0566 - val_accuracy: 0.9800\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0606 - accuracy: 0.9688 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1002 - accuracy: 0.9688 - val_loss: 0.0641 - val_accuracy: 0.9600\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0917 - accuracy: 0.9812 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0580 - accuracy: 0.9875 - val_loss: 0.0741 - val_accuracy: 0.9800\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.1044 - accuracy: 0.9688 - val_loss: 0.0310 - val_accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0781 - accuracy: 0.9688 - val_loss: 0.0499 - val_accuracy: 0.9800\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0497 - accuracy: 0.9750 - val_loss: 0.0583 - val_accuracy: 0.9800\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0552 - accuracy: 0.9750 - val_loss: 0.0663 - val_accuracy: 0.9600\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0966 - accuracy: 0.9625 - val_loss: 0.1012 - val_accuracy: 0.9400\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.0131 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#모델을 실행합니다\n",
    "history = model.fit(\n",
    "       train_generator,\n",
    "       epochs=100,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10, \n",
    "       callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28769753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy', 'val_loss', 'val_accuracy']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ce3054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrame in module pandas.core.frame:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame)\n",
      " |  DataFrame(data=None, index: Union[Collection, NoneType] = None, columns: Union[Collection, NoneType] = None, dtype: Union[ForwardRef('ExtensionDtype'), str, numpy.dtype, Type[Union[str, float, int, complex, bool]], NoneType] = None, copy: bool = False)\n",
      " |  \n",
      " |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      " |  \n",
      " |  Data structure also contains labeled axes (rows and columns).\n",
      " |  Arithmetic operations align on both row and column labels. Can be\n",
      " |  thought of as a dict-like container for Series objects. The primary\n",
      " |  pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, or list-like objects.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23.0\n",
      " |         If data is a dict, column order follows insertion-order for\n",
      " |         Python 3.6 and later.\n",
      " |  \n",
      " |      .. versionchanged:: 0.25.0\n",
      " |         If data is a list of dicts, column order follows insertion-order\n",
      " |         for Python 3.6 and later.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool, default False\n",
      " |      Copy data from inputs. Only affects DataFrame / 2d ndarray input.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      " |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      " |  read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |  read_table : Read general delimited file into DataFrame.\n",
      " |  read_clipboard : Read text from clipboard into DataFrame.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      " |  ...                    columns=['a', 'b', 'c'])\n",
      " |  >>> df2\n",
      " |     a  b  c\n",
      " |  0  1  2  3\n",
      " |  1  4  5  6\n",
      " |  2  7  8  9\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Wrapper for comparison method __eq__\n",
      " |  \n",
      " |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Wrapper for comparison method __ge__\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Wrapper for comparison method __gt__\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __iand__(self, other)\n",
      " |  \n",
      " |  __ifloordiv__(self, other)\n",
      " |  \n",
      " |  __imod__(self, other)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index: Union[Collection, NoneType] = None, columns: Union[Collection, NoneType] = None, dtype: Union[ForwardRef('ExtensionDtype'), str, numpy.dtype, Type[Union[str, float, int, complex, bool]], NoneType] = None, copy: bool = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__(self, other)\n",
      " |  \n",
      " |  __ipow__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __ixor__(self, other)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Wrapper for comparison method __le__\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Wrapper for comparison method __lt__\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Wrapper for comparison method __ne__\n",
      " |  \n",
      " |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |  \n",
      " |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      core.groupby.GroupBy : Perform operations over groups.\n",
      " |      core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      core.window.Rolling : Perform operations over rolling window.\n",
      " |      core.window.Expanding : Perform operations over expanding window.\n",
      " |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      max   NaN  8.0\n",
      " |      min   1.0  2.0\n",
      " |      sum  12.0  NaN\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None) -> 'DataFrame'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index=False, verify_integrity=False, sort=False) -> 'DataFrame'\n",
      " |      Append rows of `other` to the end of caller, returning a new object.\n",
      " |      \n",
      " |      Columns in `other` that are not in the caller are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : bool, default False\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Changed to not sort by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      0  5  6\n",
      " |      1  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |      \n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwds\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Returning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |  \n",
      " |  applymap(self, func) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |      \n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |      \n",
      " |      .. versionchanged:: 0.23.0\n",
      " |      \n",
      " |         Keyword argument order is maintained.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |      \n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |      \n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  combine(self, other: 'DataFrame', func, fill_value=None, overwrite=True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |      \n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Example using a true element-wise combine function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |      \n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |      \n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |      \n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |  \n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |      \n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |  \n",
      " |  compare(self, other: 'DataFrame', align_axis: Union[str, int] = 1, keep_shape: bool = False, keep_equal: bool = False) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |      \n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Stack the differences on rows\n",
      " |      \n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |      \n",
      " |      Keep the equal values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |      \n",
      " |      Keep all original rows and columns\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and columns and also all original values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |  \n",
      " |  corr(self, method='pearson', min_periods=1) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      \n",
      " |              .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |  \n",
      " |  corrwith(self, other, axis=0, drop=False, method='pearson') -> pandas.core.series.Series\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n",
      " |          row-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |  \n",
      " |  count(self, axis=0, level=None, numeric_only=False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for one level of a `MultiIndex`:\n",
      " |      \n",
      " |      >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n",
      " |              Age\n",
      " |      Person\n",
      " |      John      2\n",
      " |      Lewis     1\n",
      " |      Myla      1\n",
      " |  \n",
      " |  cov(self, min_periods: Union[int, NoneType] = None, ddof: Union[int, NoneType] = 1) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ExponentialMovingWindow.cov: Exponential weighted sample covariance.\n",
      " |      core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: int = 1, axis: Union[str, int] = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Dataframe element compared with another\n",
      " |      element in the Dataframe (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataframe\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataframe.pct_change: Percent change over given number of periods.\n",
      " |      Dataframe.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Dataframe,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |      \n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |      \n",
      " |      It can also be called using ``self @ other`` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |      \n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note that the dot method give the same result as @\n",
      " |      \n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      The dot method works also if other is an np.array.\n",
      " |      \n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |      \n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame without the removed index or column labels.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset: Union[Hashable, Sequence[Hashable], NoneType] = None, keep: Union[str, bool] = 'first', inplace: bool = False, ignore_index: bool = False) -> Union[ForwardRef('DataFrame'), NoneType]\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |      \n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to drop duplicates in place or to return a copy.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |      \n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      \n",
      " |      To remove duplicates and keep last occurences, use ``keep``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |  \n",
      " |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             Pass tuple or list to drop on multiple axes.\n",
      " |             Only a single axis is allowed.\n",
      " |      \n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      \n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values.\n",
      " |      subset : array-like, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'born'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset: Union[Hashable, Sequence[Hashable], NoneType] = None, keep: Union[str, bool] = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |      \n",
      " |      Considering certain columns is optional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |      \n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  eval(self, expr, inplace=False, **kwargs)\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, or pandas object\n",
      " |          The result of the evaluation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      \n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |      \n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0, times=None)\n",
      " |      Provide exponential weighted (EW) functions.\n",
      " |      \n",
      " |      Available EW functions: ``mean()``, ``var()``, ``std()``, ``corr()``, ``cov()``.\n",
      " |      \n",
      " |      Exactly one parameter: ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, the time unit (str or timedelta) over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights; specify ``True`` to reproduce\n",
      " |          pre-0.15.0 behavior.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True`` (reproducing pre-0.15.0 behavior), weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      axis : {0, 1}, default 0\n",
      " |          The axis to use. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      times : str, np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If str, the name of the column in the DataFrame representing the times.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A Window sub-classed for the particular operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      More details can be found at:\n",
      " |      :ref:`Exponentially weighted windows <stats.moments.exponentially_weighted>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Specifying ``times`` with a timedelta ``halflife`` when computing mean.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=None, axis=0)\n",
      " |      Provide expanding transformations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or str, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  explode(self, column: Union[str, Tuple], ignore_index: bool = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or tuple\n",
      " |          Column to explode.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          if columns of the frame are not unique.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged. Empty list-likes will\n",
      " |      result in a np.nan for that row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[1, 2, 3], 'foo', [], [3, 4]], 'B': 1})\n",
      " |      >>> df\n",
      " |                 A  B\n",
      " |      0  [1, 2, 3]  1\n",
      " |      1        foo  1\n",
      " |      2         []  1\n",
      " |      3     [3, 4]  1\n",
      " |      \n",
      " |      >>> df.explode('A')\n",
      " |           A  B\n",
      " |      0    1  1\n",
      " |      0    2  1\n",
      " |      0    3  1\n",
      " |      1  foo  1\n",
      " |      2  NaN  1\n",
      " |      3    3  1\n",
      " |      3    4  1\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) -> Union[ForwardRef('DataFrame'), NoneType]\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = <object object at 0x7f8a6c5f2e20>, observed: bool = False, dropna: bool = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1).\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply, add group keys to index to identify pieces.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |      \n",
      " |      **Hierarchical Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |      \n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`:\n",
      " |      \n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |      \n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  hist = hist_frame(data: 'DataFrame', column: Union[Hashable, NoneType, Sequence[Union[Hashable, NoneType]]] = None, by=None, grid: bool = True, xlabelsize: Union[int, NoneType] = None, xrot: Union[float, NoneType] = None, ylabelsize: Union[int, NoneType] = None, yrot: Union[float, NoneType] = None, ax=None, sharex: bool = False, sharey: bool = False, figsize: Union[Tuple[int, int], NoneType] = None, layout: Union[Tuple[int, int], NoneType] = None, bins: Union[int, Sequence[int]] = 10, backend: Union[str, NoneType] = None, legend: bool = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True) -> pandas.core.series.Series\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True) -> pandas.core.series.Series\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  info(self, verbose: Union[bool, NoneType] = None, buf: Union[IO[str], NoneType] = None, max_cols: Union[int, NoneType] = None, memory_usage: Union[bool, str, NoneType] = None, null_counts: Union[bool, NoneType] = None) -> None\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          DataFrame to print information about.\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |                      When to switch from the verbose to the truncated output. If the\n",
      " |                      DataFrame has more than `max_cols` columns, the truncated output\n",
      " |                      is used. By default, the setting in\n",
      " |                      ``pandas.options.display.max_info_columns`` is used.\n",
      " |                  \n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources.\n",
      " |      null_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      \n",
      " |                  DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |                      columns.\n",
      " |                  DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |                  >>> int_values = [1, 2, 3, 4, 5]\n",
      " |                  >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |                  >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |                  >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |                  ...                   \"float_col\": float_values})\n",
      " |                  >>> df\n",
      " |                      int_col text_col  float_col\n",
      " |                  0        1    alpha       0.00\n",
      " |                  1        2     beta       0.25\n",
      " |                  2        3    gamma       0.50\n",
      " |                  3        4    delta       0.75\n",
      " |                  4        5  epsilon       1.00\n",
      " |      \n",
      " |                  Prints information of all columns:\n",
      " |      \n",
      " |                  >>> df.info(verbose=True)\n",
      " |                  <class 'pandas.core.frame.DataFrame'>\n",
      " |                  RangeIndex: 5 entries, 0 to 4\n",
      " |                  Data columns (total 3 columns):\n",
      " |                   #   Column     Non-Null Count  Dtype\n",
      " |                  ---  ------     --------------  -----\n",
      " |                   0   int_col    5 non-null      int64\n",
      " |                   1   text_col   5 non-null      object\n",
      " |                   2   float_col  5 non-null      float64\n",
      " |                  dtypes: float64(1), int64(1), object(1)\n",
      " |                  memory usage: 248.0+ bytes\n",
      " |      \n",
      " |                  Prints a summary of columns count and its dtypes but not per column\n",
      " |                  information:\n",
      " |      \n",
      " |                  >>> df.info(verbose=False)\n",
      " |                  <class 'pandas.core.frame.DataFrame'>\n",
      " |                  RangeIndex: 5 entries, 0 to 4\n",
      " |                  Columns: 3 entries, int_col to float_col\n",
      " |                  dtypes: float64(1), int64(1), object(1)\n",
      " |                  memory usage: 248.0+ bytes\n",
      " |      \n",
      " |                  Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |                  buffer content and writes to a text file:\n",
      " |      \n",
      " |                  >>> import io\n",
      " |                  >>> buffer = io.StringIO()\n",
      " |                  >>> df.info(buf=buffer)\n",
      " |                  >>> s = buffer.getvalue()\n",
      " |                  >>> with open(\"df_info.txt\", \"w\",\n",
      " |                  ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |                  ...     f.write(s)\n",
      " |                  260\n",
      " |      \n",
      " |                  The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |                  useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |                  >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |                  >>> df = pd.DataFrame({\n",
      " |                  ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |                  ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |                  ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |                  ... })\n",
      " |                  >>> df.info()\n",
      " |                  <class 'pandas.core.frame.DataFrame'>\n",
      " |                  RangeIndex: 1000000 entries, 0 to 999999\n",
      " |                  Data columns (total 3 columns):\n",
      " |                   #   Column    Non-Null Count    Dtype\n",
      " |                  ---  ------    --------------    -----\n",
      " |                   0   column_1  1000000 non-null  object\n",
      " |                   1   column_2  1000000 non-null  object\n",
      " |                   2   column_3  1000000 non-null  object\n",
      " |                  dtypes: object(3)\n",
      " |                  memory usage: 22.9+ MB\n",
      " |      \n",
      " |                  >>> df.info(memory_usage='deep')\n",
      " |                  <class 'pandas.core.frame.DataFrame'>\n",
      " |                  RangeIndex: 1000000 entries, 0 to 999999\n",
      " |                  Data columns (total 3 columns):\n",
      " |                   #   Column    Non-Null Count    Dtype\n",
      " |                  ---  ------    --------------    -----\n",
      " |                   0   column_1  1000000 non-null  object\n",
      " |                   1   column_2  1000000 non-null  object\n",
      " |                   2   column_3  1000000 non-null  object\n",
      " |                  dtypes: object(3)\n",
      " |                  memory usage: 188.8 MB\n",
      " |  \n",
      " |  insert(self, loc, column, value, allow_duplicates=False) -> None\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : int, Series, or array-like\n",
      " |      allow_duplicates : bool, optional\n",
      " |  \n",
      " |  isin(self, values) -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      \n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |      \n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |      \n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in df2.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 2], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False      False\n",
      " |  \n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> Iterable[Tuple[Union[Hashable, NoneType], pandas.core.series.Series]]\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iteritems(self) -> Iterable[Tuple[Union[Hashable, NoneType], pandas.core.series.Series]]\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iterrows(self) -> Iterable[Tuple[Union[Hashable, NoneType], pandas.core.series.Series]]\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |      \n",
      " |      it : generator\n",
      " |          A generator that iterates over the rows of the frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |  \n",
      " |  itertuples(self, index=True, name='Pandas')\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      On python versions < 3.7 regular tuples are returned for DataFrames\n",
      " |      with a large number of columns (>254).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |  \n",
      " |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |      \n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it.\n",
      " |            lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  lookup(self, row_labels, col_labels) -> numpy.ndarray\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      \n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup.\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The found values.\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default None\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values for the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This isthe equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |      \n",
      " |      Max using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.max(level='blooded')\n",
      " |      blooded\n",
      " |      warm    4\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max(level=0)\n",
      " |      blooded\n",
      " |      warm    4\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or str, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      Original index values can be kept around:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False) -> pandas.core.series.Series\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0    1.000000+0.000000j       1  True\n",
      " |      1      1      1.0    1.000000+0.000000j       1  True\n",
      " |      2      1      1.0    1.000000+0.000000j       1  True\n",
      " |      3      1      1.0    1.000000+0.000000j       1  True\n",
      " |      4      1      1.0    1.000000+0.000000j       1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        160000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5216\n",
      " |  \n",
      " |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |      \n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |      \n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |      \n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      Support for merging named Series objects was added in version 0.24.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |      \n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  foo        5  foo        5\n",
      " |      3  foo        5  foo        8\n",
      " |      4  bar        2  bar        6\n",
      " |      5  baz        3  baz        7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  foo           5  foo            5\n",
      " |      3  foo           5  foo            8\n",
      " |      4  bar           2  bar            6\n",
      " |      5  baz           3  baz            7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values for the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This isthe equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |      \n",
      " |      Min using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.min(level='blooded')\n",
      " |      blooded\n",
      " |      warm    2\n",
      " |      cold    0\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min(level=0)\n",
      " |      blooded\n",
      " |      warm    2\n",
      " |      cold    0\n",
      " |      Name: legs, dtype: int64\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  mode(self, axis=0, numeric_only=False, dropna=True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |      \n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |      \n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |      \n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. The second row of species and legs contains ``NaN``,\n",
      " |      because they have only one mode, but the DataFrame has two rows.\n",
      " |      \n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |      \n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |      \n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |      \n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |      \n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |      \n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |      \n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `=!`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  nlargest(self, n, columns, keep='first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - `first` : prioritize the first occurrence(s)\n",
      " |          - `last` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |                      selecting more than `n` items.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      \n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |  \n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n, columns, keep='first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036          IS\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |      \n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |  \n",
      " |  nunique(self, axis=0, dropna=True) -> pandas.core.series.Series\n",
      " |      Count distinct observations over requested axis.\n",
      " |      \n",
      " |      Return Series with number of distinct observations. Can ignore NaN\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of index names.\n",
      " |      \n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of columns names.\n",
      " |      \n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |             Also accept list of column names.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |      \n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"],values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |      \n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      \n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals).\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |      \n",
      " |      This first example aggregates values by taking the sum.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |      \n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': np.mean})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |      \n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                      D    E\n",
      " |                  mean  max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000  9.0  7.500000  6.0\n",
      " |          small  5.500000  9.0  8.500000  8.0\n",
      " |      foo large  2.000000  5.0  4.500000  4.0\n",
      " |          small  2.333333  6.0  4.333333  2.0\n",
      " |  \n",
      " |  pop(self, item: Union[Hashable, NoneType]) -> pandas.core.series.Series\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded:: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  query(self, expr, inplace=False, **kwargs)\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |      \n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      \n",
      " |          You can refer to column names that contain spaces or operators by\n",
      " |          surrounding them in backticks. This way you can also escape\n",
      " |          names that start with a digit, or those that  are a Python keyword.\n",
      " |          Basically when it is not valid Python identifier. See notes down\n",
      " |          for more details.\n",
      " |      \n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Backtick quoting introduced.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |              Expanding functionality of backtick quoting for more than only spaces.\n",
      " |      \n",
      " |      inplace : bool\n",
      " |          Whether the query should modify the data in place or return\n",
      " |          a modified copy.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame resulting from the provided query expression.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      *Backtick quoted variables*\n",
      " |      \n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |      \n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |      \n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |      \n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |      \n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform Series/DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keywords for axes : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or functions transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with the renamed axis labels.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Rename columns using a mapping:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Rename index using a mapping:\n",
      " |      \n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |      \n",
      " |      Cast index labels to a different type:\n",
      " |      \n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |      \n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |      \n",
      " |      Using axis-style parameters\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order, axis=0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level: Union[Hashable, Sequence[Hashable], NoneType] = None, drop: bool = False, inplace: bool = False, col_level: Hashable = 0, col_fill: Union[Hashable, NoneType] = '') -> Union[ForwardRef('DataFrame'), NoneType]\n",
      " |      Reset the index, or a level of it.\n",
      " |      \n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the DataFrame in place (do not create a new object).\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |      \n",
      " |          If a BaseIndexer subclass is passed, calculates the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely `min_periods`, `center`, and\n",
      " |          `closed` will be passed to `get_window_bounds`.\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          `min_periods` will default to 1. Otherwise, `min_periods` will default\n",
      " |          to the size of the window.\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : str, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a datetime-like column or MultiIndex level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      axis : int or str, default 0\n",
      " |      closed : str, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs parameter: beta)\n",
      " |      * ``gaussian`` (needs parameter: std)\n",
      " |      * ``general_gaussian`` (needs parameters: power, width)\n",
      " |      * ``slepian`` (needs parameter: width)\n",
      " |      * ``exponential`` (needs parameter: tau), center is set to None.\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      Certain window types require additional parameters to be passed. Please see\n",
      " |      the third example below on how to add the additional parameters.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  0.5\n",
      " |      2  1.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'gaussian'\n",
      " |      window type (note how we need to specify std).\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Same as above, but with forward-looking windows\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |      \n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |      \n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |      \n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |      \n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |      \n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |      \n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_axis(self, labels, axis: Union[str, int] = 0, inplace: bool = False)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1 identifies the columns.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame or None\n",
      " |          An object of type DataFrame if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |              Change the row labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |      \n",
      " |              Change the column labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |      \n",
      " |              Now, update the labels inplace.\n",
      " |      \n",
      " |              >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |              >>> df\n",
      " |                 i  ii\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |  \n",
      " |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |      \n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the DataFrame in place (do not create a new object).\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Changed row labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |      \n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |      \n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Create a MultiIndex using two Series:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN  10.0  13.0\n",
      " |      2020-01-02   NaN  20.0  23.0\n",
      " |      2020-01-03   NaN  15.0  18.0\n",
      " |      2020-01-04   NaN  30.0  33.0\n",
      " |      2020-01-05   NaN  45.0  48.0\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending: bool = True, inplace: bool = False, kind: str = 'quicksort', na_position: str = 'last', sort_remaining: bool = True, ignore_index: bool = False, key: Union[Callable[[ForwardRef('Index')], Union[ForwardRef('Index'), ~AnyArrayLike]], NoneType] = None)\n",
      " |      Sort object by labels (along an axis).\n",
      " |      \n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |          information.  `mergesort` is the only stable algorithm. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The original DataFrame sorted by the labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |      \n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |      \n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |      \n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |  \n",
      " |  sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key: Union[Callable[[ForwardRef('Series')], Union[ForwardRef('Series'), ~AnyArrayLike]], NoneType] = None)\n",
      " |      Sort by the values along either axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |              by : str or list of str\n",
      " |                  Name or list of names to sort by.\n",
      " |      \n",
      " |                  - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |                    levels and/or column labels.\n",
      " |                  - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |                    levels and/or index labels.\n",
      " |      \n",
      " |                  .. versionchanged:: 0.23.0\n",
      " |      \n",
      " |                     Allow specifying index or column level names.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |           .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      \n",
      " |      Sorting with a key function\n",
      " |      \n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |  \n",
      " |  stack(self, level=-1, dropna=True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded:: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      Sum using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.sum(level='blooded')\n",
      " |      blooded\n",
      " |      warm    6\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum(level=0)\n",
      " |      blooded\n",
      " |      warm    6\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, axis=0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a MultiIndex on a particular axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |          'columns' for column-wise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  to_dict(self, orient='dict', into=<class 'dict'>)\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.Mapping\n",
      " |          Return a collections.abc.Mapping object representing the DataFrame.\n",
      " |          The resulting transformation depends on the `orient` parameter.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_feather(self, path, **kwargs) -> None\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          String file path.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          Starting with pyarrow 0.17, this includes the `compression`,\n",
      " |          `compression_level`, `chunksize` and `version` keywords.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |  \n",
      " |  to_gbq(self, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=False, table_schema=None, location=None, progress_bar=True, credentials=None) -> None\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default False\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |      \n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Ability to use str.\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of NAN to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |  \n",
      " |  to_markdown(self, buf: Union[IO[str], NoneType] = None, mode: Union[str, NoneType] = None, index: bool = True, **kwargs) -> Union[str, NoneType]\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\n",
      " |      >>> print(s.to_markdown())\n",
      " |      |    | animal   |\n",
      " |      |---:|:---------|\n",
      " |      |  0 | elk      |\n",
      " |      |  1 | pig      |\n",
      " |      |  2 | dog      |\n",
      " |      |  3 | quetzal  |\n",
      " |      \n",
      " |      Output markdown with a tabulate option.\n",
      " |      \n",
      " |      >>> print(s.to_markdown(tablefmt=\"grid\"))\n",
      " |      +----+----------+\n",
      " |      |    | animal   |\n",
      " |      +====+==========+\n",
      " |      |  0 | elk      |\n",
      " |      +----+----------+\n",
      " |      |  1 | pig      |\n",
      " |      +----+----------+\n",
      " |      |  2 | dog      |\n",
      " |      +----+----------+\n",
      " |      |  3 | quetzal  |\n",
      " |      +----+----------+\n",
      " |  \n",
      " |  to_numpy(self, dtype=None, copy: bool = False, na_value=<object object at 0x7f8a6c5f2e20>) -> numpy.ndarray\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      \n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |      \n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |      \n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |  \n",
      " |  to_parquet(self, path: Union[str, pathlib.Path, IO[~AnyStr]], engine: str = 'auto', compression: Union[str, NoneType] = 'snappy', index: Union[bool, NoneType] = None, partition_cols: Union[List[str], NoneType] = None, **kwargs) -> None\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str or file-like object\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handler\n",
      " |          (e.g. via builtin open function) or io.BytesIO. The engine\n",
      " |          fastparquet does not accept file-like objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |  \n",
      " |  to_period(self, freq=None, axis: Union[str, int] = 0, copy: bool = True) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with PeriodIndex\n",
      " |  \n",
      " |  to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> numpy.recarray\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |      \n",
      " |          This mapping is applied only if `index=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |      \n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      Data types can be specified for the columns:\n",
      " |      \n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |      \n",
      " |      As well as for the index:\n",
      " |      \n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_stata(self, path: Union[str, pathlib.Path, IO[~AnyStr]], convert_dates: Union[Dict[Union[Hashable, NoneType], str], NoneType] = None, write_index: bool = True, byteorder: Union[str, NoneType] = None, time_stamp: Union[datetime.datetime, NoneType] = None, data_label: Union[str, NoneType] = None, variable_labels: Union[Dict[Union[Hashable, NoneType], str], NoneType] = None, version: Union[int, NoneType] = 114, convert_strl: Union[Sequence[Union[Hashable, NoneType]], NoneType] = None, compression: Union[str, Mapping[str, str], NoneType] = 'infer') -> None\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |      \n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, buffer or path object\n",
      " |          String, path object (pathlib.Path or py._path.local.LocalPath) or\n",
      " |          object implementing a binary write() function. If using a buffer\n",
      " |          then the buffer will not be automatically closed after the file\n",
      " |          data has been written.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Added support for formats 118 and 119.\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output dta. If string, specifies\n",
      " |          compression mode. If dict, value at key 'method' specifies\n",
      " |          compression mode. Compression mode must be one of {'infer', 'gzip',\n",
      " |          'bz2', 'zip', 'xz', None}. If compression mode is 'infer' and\n",
      " |          `fname` is path-like, then detect compression from the following\n",
      " |          extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      " |          compression). If dict and compression mode is one of {'zip',\n",
      " |          'gzip', 'bz2'}, or inferred as one of the above, other entries\n",
      " |          passed as additional compression options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_string(self, buf: Union[str, pathlib.Path, IO[str], NoneType] = None, columns: Union[Sequence[str], NoneType] = None, col_space: Union[int, NoneType] = None, header: Union[bool, Sequence[str]] = True, index: bool = True, na_rep: str = 'NaN', formatters: Union[List[Callable], Tuple[Callable, ...], Mapping[Union[str, int], Callable], NoneType] = None, float_format: Union[str, Callable, ForwardRef('EngFormatter'), NoneType] = None, sparsify: Union[bool, NoneType] = None, index_names: bool = True, justify: Union[str, NoneType] = None, max_rows: Union[int, NoneType] = None, min_rows: Union[int, NoneType] = None, max_cols: Union[int, NoneType] = None, show_dimensions: bool = False, decimal: str = '.', line_width: Union[int, NoneType] = None, max_colwidth: Union[int, NoneType] = None, encoding: Union[str, NoneType] = None) -> Union[str, NoneType]\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or sequence, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of NAN to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how: str = 'start', axis: Union[str, int] = 0, copy: bool = True) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, axis=0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with transformed values.\n",
      " |      \n",
      " |      Produced DataFrame will have same axis length as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.exp. 'sqrt']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |  \n",
      " |  transpose(self, *args, copy: bool = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |      \n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5     8\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |      \n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |      \n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  update(self, other, join='left', overwrite=True, filter_func=None, errors='ignore') -> None\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |             Changed from `raise_conflict=False|True`\n",
      " |             to `errors='ignore'|'raise'`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None : method directly changes calling object\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, it's name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  value_counts(self, subset: Union[Sequence[Union[Hashable, NoneType]], NoneType] = None, normalize: bool = False, sort: bool = True, ascending: bool = False)\n",
      " |      Return a Series containing counts of unique rows in the DataFrame.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column. By default, rows that contain any NA values are omitted from\n",
      " |      the result. By default, the resulting Series will be in descending\n",
      " |      order so that the first element is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      2         2            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      6         0            0.25\n",
      " |      2         2            0.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data, orient='columns', dtype=None, columns=None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'``.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |      \n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |      \n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of dicts:\n",
      " |      \n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |      \n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  T\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |      \n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_AXIS_TO_AXIS_NUMBER': typing.Dict[typing.Union[st...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot\n",
      " |          - 'hexbin' : hexbin plot.\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool, default False\n",
      " |          Make separate subplots for each column.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      sort_columns : bool, default False\n",
      " |          Sort column names to determine plot ordering.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __array__(self, dtype=None) -> numpy.ndarray\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key) -> bool\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: ~FrameOrSeries, deep: bool = True) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __deepcopy__(self: ~FrameOrSeries, memo=None) -> ~FrameOrSeries\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> None\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: ~FrameOrSeries, other, method: Union[str, NoneType] = None, **kwargs) -> ~FrameOrSeries\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning:\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: str)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> Dict[str, Any]\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over info axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self: ~FrameOrSeries, decimals: int = 0) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __setattr__(self, name: str, value) -> None\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: ~FrameOrSeries, prefix: str) -> ~FrameOrSeries\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: ~FrameOrSeries, suffix: str) -> ~FrameOrSeries\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asfreq(self: ~FrameOrSeries, freq, method=None, how: Union[str, NoneType] = None, normalize: bool = False, fill_value=None) -> ~FrameOrSeries\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller\n",
      " |          Object converted to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                               a   b\n",
      " |      2018-02-27 09:03:30   30.0 NaN\n",
      " |      2018-02-27 09:04:30   40.0 NaN\n",
      " |  \n",
      " |  astype(self: ~FrameOrSeries, dtype, copy: bool = True, errors: str = 'raise') -> ~FrameOrSeries\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> cat_dtype = pd.api.types.CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      Datetimes are localized to UTC first before\n",
      " |      converting to the specified timezone:\n",
      " |      \n",
      " |      >>> ser_date.astype('datetime64[ns, US/Eastern]')\n",
      " |      0   2019-12-31 19:00:00-05:00\n",
      " |      1   2020-01-01 19:00:00-05:00\n",
      " |      2   2020-01-02 19:00:00-05:00\n",
      " |      dtype: datetime64[ns, US/Eastern]\n",
      " |  \n",
      " |  at_time(self: ~FrameOrSeries, time, asof: bool = False, axis=None) -> ~FrameOrSeries\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill = bfill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |  \n",
      " |  between_time(self: ~FrameOrSeries, start_time, end_time, include_start: bool = True, include_end: bool = True, axis=None) -> ~FrameOrSeries\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      include_start : bool, default True\n",
      " |          Whether the start time needs to be included in the result.\n",
      " |      include_end : bool, default True\n",
      " |          Whether the end time needs to be included in the result.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bfill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass} or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  clip(self: ~FrameOrSeries, lower=None, upper=None, axis=None, inplace: bool = False, *args, **kwargs) -> ~FrameOrSeries\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or str axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  convert_dtypes(self: ~FrameOrSeries, infer_objects: bool = True, convert_string: bool = True, convert_integer: bool = True, convert_boolean: bool = True) -> ~FrameOrSeries\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, and ``convert_boolean``, it is\n",
      " |      possible to turn off individual conversions to ``StringDtype``, the integer\n",
      " |      extension types or ``BooleanDtype``, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer extension\n",
      " |      type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10    NaN\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: ~FrameOrSeries, deep: bool = True) -> ~FrameOrSeries\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: ~FrameOrSeries, percentiles=None, include=None, exclude=None, datetime_is_numeric=False) -> ~FrameOrSeries\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: ~FrameOrSeries, level, axis=0) -> ~FrameOrSeries\n",
      " |      Return DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal. The column headers do not\n",
      " |      need to have the same type, but the elements within the columns must\n",
      " |      be the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires that the elements have the same dtype as their\n",
      " |      respective elements in the other Series or DataFrame. However, the\n",
      " |      column labels do not need to have the same type, as long as they are\n",
      " |      still considered equal.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ffill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass} or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  filter(self: ~FrameOrSeries, items=None, like: Union[str, NoneType] = None, regex: Union[str, NoneType] = None, axis=None) -> ~FrameOrSeries\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: ~FrameOrSeries, offset) -> ~FrameOrSeries\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |  \n",
      " |  head(self: ~FrameOrSeries, n: int = 5) -> ~FrameOrSeries\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `n` rows, equivalent to ``df[:-n]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self: ~FrameOrSeries, method: str = 'linear', axis: Union[str, int] = 0, limit: Union[int, NoneType] = None, inplace: bool = False, limit_direction: Union[str, NoneType] = None, limit_area: Union[str, NoneType] = None, downcast: Union[str, NoneType] = None, **kwargs) -> Union[~FrameOrSeries, NoneType]\n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |      and `SciPy tutorial\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |  \n",
      " |  last(self: ~FrameOrSeries, offset) -> ~FrameOrSeries\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default False\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  pad = ffill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |  \n",
      " |  pct_change(self: ~FrameOrSeries, periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> ~FrameOrSeries\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: ~FrameOrSeries, axis=0, method: str = 'average', numeric_only: Union[bool, NoneType] = None, na_option: str = 'keep', ascending: bool = True, pct: bool = False) -> ~FrameOrSeries\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign smallest rank to NaN values if ascending\n",
      " |          * bottom: assign highest rank to NaN values if ascending.\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: ~FrameOrSeries, other, method: Union[str, NoneType] = None, copy: bool = True, limit=None, tolerance=None) -> ~FrameOrSeries\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      the corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  resample(self, rule, axis=0, closed: Union[str, NoneType] = None, label: Union[str, NoneType] = None, convention: str = 'start', kind: Union[str, NoneType] = None, loffset=None, base: Union[int, NoneType] = None, on=None, level=None, origin: Union[str, ForwardRef('Timestamp'), datetime.datetime, numpy.datetime64, int, numpy.int64, float] = 'start_day', offset: Union[ForwardRef('Timedelta'), datetime.timedelta, numpy.timedelta64, int, numpy.int64, float, str, NoneType] = None) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series. Object must have a datetime-like index (`DatetimeIndex`,\n",
      " |      `PeriodIndex`, or `TimedeltaIndex`), or pass datetime-like values\n",
      " |      to the `on` or `level` keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this\n",
      " |          will default to 0, i.e. along the rows. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              You should add the loffset to the `df.index` after the resample.\n",
      " |              See below.\n",
      " |      \n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              The new arguments that you should use are 'offset' or 'origin'.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : {'epoch', 'start', 'start_day'}, Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If a timestamp is not used, these values are also supported:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample: Resample a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = dict({'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...           'volume': [50, 60, 40, 100, 50, 100, 40, 50]})\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = dict({'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...            'volume': [50, 60, 40, 100, 50, 100, 40, 50]})\n",
      " |      >>> df2 = pd.DataFrame(d2,\n",
      " |      ...                    index=pd.MultiIndex.from_product([days,\n",
      " |      ...                                                     ['morning',\n",
      " |      ...                                                      'afternoon']]\n",
      " |      ...                                                     ))\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      " |      in this example it is equivalent to have `base=2`:\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='2min').sum()\n",
      " |      2000-10-01 23:16:00     0\n",
      " |      2000-10-01 23:33:00     9\n",
      " |      2000-10-01 23:50:00    36\n",
      " |      2000-10-02 00:07:00    39\n",
      " |      2000-10-02 00:24:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `loffset` argument:\n",
      " |      \n",
      " |      >>> from pandas.tseries.frequencies import to_offset\n",
      " |      >>> loffset = '19min'\n",
      " |      >>> ts_out = ts.resample('17min').sum()\n",
      " |      >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      " |      >>> ts_out\n",
      " |      2000-10-01 23:33:00     0\n",
      " |      2000-10-01 23:50:00     9\n",
      " |      2000-10-02 00:07:00    21\n",
      " |      2000-10-02 00:24:00    54\n",
      " |      2000-10-02 00:41:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  sample(self: ~FrameOrSeries, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None) -> ~FrameOrSeries\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, optional\n",
      " |          If int, array-like, or BitGenerator (NumPy>=1.17), seed for\n",
      " |          random number generator\n",
      " |          If np.random.RandomState, use as numpy RandomState object.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator (for NumPy>=1.17) object now passed to\n",
      " |              np.random.RandomState() as seed\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  slice_shift(self: ~FrameOrSeries, periods: int = 1, axis=0) -> ~FrameOrSeries\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      \n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: ~FrameOrSeries, axis1, axis2, copy=True) -> ~FrameOrSeries\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: ~FrameOrSeries, n: int = 5) -> ~FrameOrSeries\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `n` rows, equivalent to ``df[n:]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  take(self: ~FrameOrSeries, indices, axis=0, is_copy: Union[bool, NoneType] = None, **kwargs) -> ~FrameOrSeries\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel: bool = True, sep: Union[str, NoneType] = None, **kwargs) -> None\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: Union[str, pathlib.Path, IO[~AnyStr], NoneType] = None, sep: str = ',', na_rep: str = '', float_format: Union[str, NoneType] = None, columns: Union[Sequence[Union[Hashable, NoneType]], NoneType] = None, header: Union[bool, List[str]] = True, index: bool = True, index_label: Union[bool, str, Sequence[Union[Hashable, NoneType]], NoneType] = None, mode: str = 'w', encoding: Union[str, NoneType] = None, compression: Union[str, Mapping[str, str], NoneType] = 'infer', quoting: Union[int, NoneType] = None, quotechar: str = '\"', line_terminator: Union[str, NoneType] = None, chunksize: Union[int, NoneType] = None, date_format: Union[str, NoneType] = None, doublequote: bool = True, escapechar: Union[str, NoneType] = None, decimal: Union[str, NoneType] = '.', errors: str = 'strict') -> Union[str, NoneType]\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      .. versionchanged:: 0.24.0\n",
      " |          The order of arguments for Series was changed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.  If a file object is passed it should be opened with\n",
      " |          `newline=''`, disabling universal newlines.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |             Was previously named \"path\" for Series.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, default None\n",
      " |          Format string for floating point numbers.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |             Previously defaulted to False for Series.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          If str, represents compression mode. If dict, value at 'method' is\n",
      " |          the compression mode. Compression mode may be any of the following\n",
      " |          possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      " |          compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      " |          detect compression mode from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      " |          and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
      " |          one of the above, other entries passed as\n",
      " |          additional compression options.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip' and 'bz2'\n",
      " |             as well as 'zip'.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      line_terminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None) -> None\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : str or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible write further data\n",
      " |      without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key: str, mode: str = 'a', complevel: Union[int, NoneType] = None, complib: Union[str, NoneType] = None, append: bool = False, format: Union[str, NoneType] = None, index: bool = True, min_itemsize: Union[int, Dict[str, int], NoneType] = None, nan_rep=None, dropna: Union[bool, NoneType] = None, data_columns: Union[bool, List[str], NoneType] = None, errors: str = 'strict', encoding: str = 'UTF-8') -> None\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\"\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf: Union[str, pathlib.Path, IO[~AnyStr], NoneType] = None, orient: Union[str, NoneType] = None, date_format: Union[str, NoneType] = None, double_precision: int = 10, force_ascii: bool = True, date_unit: str = 'ms', default_handler: Union[Callable[[Any], Union[str, int, float, bool, List, Dict, NoneType]], NoneType] = None, lines: bool = False, compression: Union[str, NoneType] = 'infer', index: bool = True, indent: Union[int, NoneType] = None) -> Union[str, NoneType]\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split','records','index','table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}\n",
      " |      \n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename. By default, the\n",
      " |          compression is inferred from the filename.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |             'infer' option added and set to default\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import json\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"0.20.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None)\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table/tabular.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str, optional\n",
      " |          The LaTeX caption to be placed inside ``\\caption{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +NORMALIZE_WHITESPACE\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path, compression: Union[str, NoneType] = 'infer', protocol: int = 4) -> None\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name: str, con, schema=None, if_exists: str = 'fail', index: bool = True, index_label=None, chunksize=None, dtype=None, method=None) -> None\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to to `con`:\n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (animal: 2, date: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: ~FrameOrSeries, before=None, after=None, axis=None, copy: bool = True) -> ~FrameOrSeries\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: ~FrameOrSeries, periods: int = 1, freq=None, axis: Union[str, int] = 0) -> ~FrameOrSeries\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: ~FrameOrSeries, tz, axis=0, level=None, copy: bool = True) -> ~FrameOrSeries\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass}\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: ~FrameOrSeries, tz, axis=0, level=None, copy: bool = True, ambiguous='raise', nonexistent: str = 'raise') -> ~FrameOrSeries\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default False\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level: bool = True)\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes on this object.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether DataFrame is empty.\n",
      " |      \n",
      " |      True if DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If 'label' does not exist in DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      Series.at : Access a single value using a label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdd69f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  val_loss  accuracy  val_accuracy\n",
       "0  0.72      0.69      0.49          0.48\n",
       "1  0.69      0.69      0.52          0.54\n",
       "2  0.69      0.69      0.53          0.58\n",
       "3  0.68      0.67      0.62          0.62\n",
       "4  0.65      0.64      0.60          0.62"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history.history\n",
    "\n",
    "pd1 = pd.DataFrame(data=np.round(history.history['loss'],2), columns=['loss'])\n",
    "pd1['val_loss'] = np.round(history.history['val_loss'],2)\n",
    "pd1['accuracy'] = np.round(history.history['accuracy'],2)\n",
    "pd1['val_accuracy'] = np.round(history.history['val_accuracy'],2)\n",
    "\n",
    "pd1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "913ccad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 검증셋과 학습셋의 오차를 저장합니다.\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현해 봅니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다.\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0d03ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 검증셋과 학습셋의 오차를 저장합니다.\n",
    "y_val_accuracy = history.history['val_accuracy']\n",
    "y_accuracy = history.history['accuracy']\n",
    "\n",
    "# 그래프로 표현해 봅니다.\n",
    "x_len = np.arange(len(y_accuracy))\n",
    "plt.plot(x_len, y_val_accuracy, marker='.', c=\"red\", label='Testset_accuracy')\n",
    "plt.plot(x_len, y_accuracy, marker='.', c=\"blue\", label='Trainset_accuray')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다.\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca527ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
