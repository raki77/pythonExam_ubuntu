{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def stitch_images(image_paths, output_path):\n",
    "    # Load images into a list\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f'Image load failed for {img_path}!')\n",
    "            return\n",
    "        images.append(img)\n",
    "    \n",
    "    # Check if we have enough images\n",
    "    if len(images) < 2:\n",
    "        print('Not enough images to stitch. Please provide at least two images.')\n",
    "        return\n",
    "    \n",
    "    # Create a Stitcher object and stitch the images\n",
    "    stitcher = cv2.Stitcher_create()\n",
    "    status, stitched_image = stitcher.stitch(images)\n",
    "    \n",
    "    if status != cv2.Stitcher_OK:\n",
    "        print(f'Error on stitching! Status code: {status}')\n",
    "        return\n",
    "    \n",
    "    # Save the stitched image\n",
    "    if not cv2.imwrite(output_path, stitched_image):\n",
    "        print(f'Failed to save image to {output_path}!')\n",
    "        return\n",
    "    \n",
    "    # Display the stitched image\n",
    "    cv2.imshow('Stitched Image', stitched_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_paths = ['../data/img/mol1.png', '../data/img/mol2.png', '../data/img/mol3.png']  # Replace with your image paths\n",
    "output_path = '../data/img/resultStitched.png'\n",
    "stitch_images(image_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def stitch_images(image_paths, output_path):\n",
    "    # Load images into a list\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f'Image load failed for {img_path}!')\n",
    "            return\n",
    "        images.append(img)\n",
    "    \n",
    "    # Check if we have enough images\n",
    "    if len(images) < 2:\n",
    "        print('Not enough images to stitch. Please provide at least two images.')\n",
    "        return\n",
    "    \n",
    "    # Create a Stitcher object and stitch the images\n",
    "    stitcher = cv2.Stitcher_create()\n",
    "    status, stitched_image = stitcher.stitch(images)\n",
    "    \n",
    "    if status != cv2.Stitcher_OK:\n",
    "        print(f'Error on stitching! Status code: {status}')\n",
    "        return\n",
    "    \n",
    "    # Save the stitched image\n",
    "    if not cv2.imwrite(output_path, stitched_image):\n",
    "        print(f'Failed to save image to {output_path}!')\n",
    "        return\n",
    "    \n",
    "    # Display the stitched image\n",
    "    cv2.imshow('Stitched Image', stitched_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_paths = ['../data/img/mol1.png', '../data/img/mol2.png', '../data/img/mol3.png']  # Replace with your image paths\n",
    "output_path = '../data/img/resultStitched.png'\n",
    "stitch_images(image_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def stitch_images(image_paths, output_path):\n",
    "    # Load images into a list\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f'Image load failed for {img_path}!')\n",
    "            return\n",
    "        images.append(img)\n",
    "    \n",
    "    # Check if we have enough images\n",
    "    if len(images) < 2:\n",
    "        print('Not enough images to stitch. Please provide at least two images.')\n",
    "        return\n",
    "    \n",
    "    # Create a Stitcher object and stitch the images\n",
    "    stitcher = cv2.Stitcher_create()\n",
    "    status, stitched_image = stitcher.stitch(images)\n",
    "    \n",
    "    if status != cv2.Stitcher_OK:\n",
    "        print(f'Error on stitching! Status code: {status}')\n",
    "        if status == cv2.Stitcher_ERR_NEED_MORE_IMGS:\n",
    "            print('You may need to provide more images or ensure that images have sufficient overlap.')\n",
    "        return\n",
    "    \n",
    "    # Save the stitched image\n",
    "    if not cv2.imwrite(output_path, stitched_image):\n",
    "        print(f'Failed to save image to {output_path}!')\n",
    "        return\n",
    "    \n",
    "    # Display the stitched image\n",
    "    cv2.imshow('Stitched Image', stitched_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_paths = ['../data/img/mol1.png', '../data/img/mol2.png', '../data/img/mol3.png']  # Replace with your image paths\n",
    "output_path = '../data/img/resultStitched.png'\n",
    "stitch_images(image_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def stitch_images(image_paths, output_path):\n",
    "    # Load images into a list\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f'Image load failed for {img_path}!')\n",
    "            return\n",
    "        images.append(img)\n",
    "    \n",
    "    # Check if we have enough images\n",
    "    if len(images) < 2:\n",
    "        print('Not enough images to stitch. Please provide at least two images.')\n",
    "        return\n",
    "    \n",
    "    # Create a Stitcher object and stitch the images\n",
    "    stitcher = cv2.Stitcher_create()\n",
    "    status, stitched_image = stitcher.stitch(images)\n",
    "    \n",
    "    if status != cv2.Stitcher_OK:\n",
    "        print(f'Error on stitching! Status code: {status}')\n",
    "        if status == cv2.Stitcher_ERR_NEED_MORE_IMGS:\n",
    "            print('You may need to provide more images or ensure that images have sufficient overlap.')\n",
    "        return\n",
    "    \n",
    "    # Save the stitched image\n",
    "    if not cv2.imwrite(output_path, stitched_image):\n",
    "        print(f'Failed to save image to {output_path}!')\n",
    "        return\n",
    "    \n",
    "    # Display the stitched image\n",
    "    cv2.imshow('Stitched Image', stitched_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage with test images\n",
    "image_paths = ['../data/img/xxx1.png', '../data/img/xxx2.png', '../data/img/xxx3.png']  # Replace with your image paths\n",
    "output_path = '../data/img/resultStitched.png'\n",
    "stitch_images(image_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#영상 읽어서 그레이 스케일로 변환\n",
    "img = cv2.imread('../data/img/pistol.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 8x8 크기로 축소 ---①\n",
    "gray = cv2.resize(gray, (16,16))\n",
    "# 영상의 평균값 구하기 ---②\n",
    "avg = gray.mean()\n",
    "# 평균값을 기준으로 0과 1로 변환 ---③\n",
    "bin = 1 * (gray > avg)\n",
    "print(bin)\n",
    "\n",
    "# 2진수 문자열을 16진수 문자열로 변환 ---④\n",
    "dhash = []\n",
    "for row in bin.tolist():\n",
    "    s = ''.join([str(i) for i in row])\n",
    "    dhash.append('%02x'%(int(s,2)))\n",
    "dhash = ''.join(dhash)\n",
    "print(dhash)\n",
    "\n",
    "cv2.namedWindow('pistol', cv2.WINDOW_GUI_NORMAL)\n",
    "cv2.imshow('pistol', img)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해밍거리 찾는법\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# 영상 읽기 및 표시\n",
    "img = cv2.imread('../data/img/black_cat.png')\n",
    "cv2.imshow('query', img)\n",
    "\n",
    "# 비교할 영상들이 있는 경로 ---①\n",
    "search_dir = '../data/101_ObjectCategories'\n",
    "\n",
    "# 이미지를 16x16 크기의 평균 해쉬로 변환 ---②\n",
    "def img2hash(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (16, 16))\n",
    "    avg = gray.mean()\n",
    "    bi = 1 * (gray > avg)\n",
    "    return bi\n",
    "\n",
    "# 해밍거리 측정 함수 ---③\n",
    "def hamming_distance(a, b):\n",
    "    a = a.reshape(1,-1)\n",
    "    b = b.reshape(1,-1)\n",
    "    # 같은 자리의 값이 서로 다른 것들의 합\n",
    "    distance = (a !=b).sum()\n",
    "    return distance\n",
    "\n",
    "# 권총 영상의 해쉬 구하기 ---④\n",
    "query_hash = img2hash(img)\n",
    "\n",
    "# 이미지 데이타 셋 디렉토리의 모든 영상 파일 경로 ---⑤\n",
    "img_path = glob.glob(search_dir+'/**/*.jpg')\n",
    "for path in img_path:\n",
    "    # 데이타 셋 영상 한개 읽어서 표시 ---⑥\n",
    "    img = cv2.imread(path)\n",
    "    cv2.imshow('searching...', img)\n",
    "    cv2.waitKey(5)\n",
    "    # 데이타 셋 영상 한개의 해시  ---⑦\n",
    "    a_hash = img2hash(img)\n",
    "    # 해밍 거리 산출 ---⑧\n",
    "    dst = hamming_distance(query_hash, a_hash)\n",
    "    # if dst/256 < 0.25: # 해밍거리 25% 이내만 출력 ---⑨\n",
    "    if dst/256 < 0.05: # 해밍거리 5% 이내만 출력 ---⑨\n",
    "        print(path, dst/256)\n",
    "        cv2.imshow(path, img)\n",
    "cv2.destroyWindow('searching...')\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "# 플로우 결과 그리기 ---①\n",
    "def drawFlow(img,flow,step=16):\n",
    "  h,w = img.shape[:2]\n",
    "  # 16픽셀 간격의 그리드 인덱스 구하기 ---②\n",
    "  idx_y,idx_x = np.mgrid[step/2:h:step,step/2:w:step].astype(np.int)\n",
    "  indices =  np.stack( (idx_x,idx_y), axis =-1).reshape(-1,2)\n",
    "  \n",
    "  for x,y in indices:   # 인덱스 순회\n",
    "    # 각 그리드 인덱스 위치에 점 그리기 ---③\n",
    "    cv2.circle(img, (x,y), 1, (0,255,0), -1)\n",
    "    # 각 그리드 인덱스에 해당하는 플로우 결과 값 (이동 거리)  ---④\n",
    "    dx,dy = flow[y, x].astype(np.int)\n",
    "    # 각 그리드 인덱스 위치에서 이동한 거리 만큼 선 그리기 ---⑤\n",
    "    cv2.line(img, (x,y), (x+dx, y+dy), (0,255, 0),2, cv2.LINE_AA )\n",
    "\n",
    "\n",
    "prev = None # 이전 프레임 저장 변수\n",
    "\n",
    "cap = cv2.VideoCapture('../data/img/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret,frame = cap.read()\n",
    "  if not ret: break\n",
    "  gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "  # 최초 프레임 경우 \n",
    "  if prev is None: \n",
    "    prev = gray # 첫 이전 프레임 --- ⑥\n",
    "  else:\n",
    "    # 이전, 이후 프레임으로 옵티컬 플로우 계산 ---⑦\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev,gray,None,\\\n",
    "                0.5,3,15,3,5,1.1,cv2.OPTFLOW_FARNEBACK_GAUSSIAN) \n",
    "    # 계산 결과 그리기, 선언한 함수 호출 ---⑧\n",
    "    drawFlow(frame,flow)\n",
    "    # 다음 프레임을 위해 이월 ---⑨\n",
    "    prev = gray\n",
    "  \n",
    "  cv2.imshow('OpticalFlow-Farneback', frame)\n",
    "  if cv2.waitKey(delay) == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Camera!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# 검색 설정 변수\n",
    "ratio = 0.7  # 좋은 매칭을 선별하기 위한 비율\n",
    "MIN_MATCH = 10  # 최소 매칭 개수\n",
    "\n",
    "# ORB 특징 검출기 생성\n",
    "detector = cv2.ORB_create()\n",
    "\n",
    "# Flann 매칭기 객체 생성\n",
    "FLANN_INDEX_LSH = 6  # LSH (Locality Sensitive Hashing) 알고리즘 인덱스\n",
    "index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "search_params = dict(checks=32)  # 매칭 체크 수\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# 책 표지 검색 함수\n",
    "def serch(img):\n",
    "    gray1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 입력 이미지의 그레이스케일 변환\n",
    "    kp1, desc1 = detector.detectAndCompute(gray1, None)  # 특징점 검출 및 기술자 계산\n",
    "    \n",
    "    results = {}  # 검색 결과를 저장할 딕셔너리\n",
    "\n",
    "    # 책 커버 보관 디렉토리 경로\n",
    "    cover_paths = glob.glob('../data/img/books/*.*')  # 책 표지 이미지 파일 경로 목록\n",
    "    for cover_path in cover_paths:\n",
    "        cover = cv2.imread(cover_path)  # 책 표지 이미지 로드\n",
    "        cv2.imshow('Searching...', cover)  # 검색 중인 책 표지 표시\n",
    "        cv2.waitKey(5)  # 잠시 대기\n",
    "        gray2 = cv2.cvtColor(cover, cv2.COLOR_BGR2GRAY)  # 책 표지 이미지의 그레이스케일 변환\n",
    "        kp2, desc2 = detector.detectAndCompute(gray2, None)  # 특징점 검출 및 기술자 계산\n",
    "        matches = matcher.knnMatch(desc1, desc2, 2)  # KNN 매칭\n",
    "\n",
    "        # 좋은 매칭 선별\n",
    "        good_matches = [m[0] for m in matches if len(m) == 2 and m[0].distance < m[1].distance * ratio]\n",
    "        if len(good_matches) > MIN_MATCH:\n",
    "            # 좋은 매칭점으로 원본과 대상 영상의 좌표 구하기\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "            # 원근 변환 행렬 구하기\n",
    "            mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            # 원근 변환 결과에서 정상치 비율 계산\n",
    "            accuracy = float(mask.sum()) / mask.size\n",
    "            results[cover_path] = accuracy  # 결과 저장\n",
    "\n",
    "    cv2.destroyWindow('Searching...')  # 검색 중인 창 닫기\n",
    "    if len(results) > 0:\n",
    "        results = sorted([(v, k) for (k, v) in results.items() if v > 0], reverse=True)  # 결과를 정확도 기준으로 정렬\n",
    "    return results\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 카메라 캡처 객체 생성\n",
    "qImg = None\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # 프레임 읽기\n",
    "    if not ret:\n",
    "        print('No Frame!')\n",
    "        break\n",
    "    h, w = frame.shape[:2]\n",
    "    # 화면에 책을 인식할 영역 표시\n",
    "    left = w // 3\n",
    "    right = (w // 3) * 2\n",
    "    top = (h // 2) - (h // 3)\n",
    "    bottom = (h // 2) + (h // 3)\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 3)  # 인식 영역을 흰색 사각형으로 표시\n",
    "    \n",
    "    # 거울 처럼 보기 좋게 화면 뒤집어 보이기\n",
    "    flip = cv2.flip(frame, 1)\n",
    "    cv2.imshow('Book Searcher', flip)  # 영상 표시\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(' '):  # 스페이스-바를 눌러서 사진 찍기\n",
    "        qImg = frame[top:bottom, left:right]  # 관심 영역 잘라내기\n",
    "        cv2.imshow('query', qImg)  # 찍은 이미지 표시\n",
    "        break\n",
    "    elif key == 27:  # Esc 키를 눌러 종료\n",
    "        break\n",
    "else:\n",
    "    print('No Camera!!')\n",
    "cap.release()  # 카메라 자원 해제\n",
    "\n",
    "if qImg is not None:\n",
    "    gray = cv2.cvtColor(qImg, cv2.COLOR_BGR2GRAY)  # 찍은 이미지의 그레이스케일 변환\n",
    "    results = serch(qImg)  # 책 표지 검색\n",
    "    if len(results) == 0:\n",
    "        print(\"No matched book cover found.\")\n",
    "    else:\n",
    "        for i, (accuracy, cover_path) in enumerate(results):\n",
    "            print(i, cover_path, accuracy)  # 검색 결과 출력\n",
    "            if i == 0:\n",
    "                cover = cv2.imread(cover_path)  # 가장 일치하는 책 표지 이미지 로드\n",
    "                cv2.putText(cover, (\"Accuracy:%.2f%%\" % (accuracy * 100)), (10, 100), \\\n",
    "                             cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)  # 정확도 표시\n",
    "        cv2.imshow('Result', cover)  # 결과 이미지 표시\n",
    "cv2.waitKey()  # 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 창 닫기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 트랙커 객체 생성자 함수 리스트 ---①\n",
    "trackers = [\n",
    "            cv2.TrackerMIL_create,\n",
    "            # cv2.TrackerKCF_create,\n",
    "            #cv2.TrackerTLD_create,\n",
    "            #cv2.TrackerMedianFlow_create,\n",
    "            cv2.TrackerGOTURN_create, #버그로 오류 발생\n",
    "            # cv2.TrackerCSRT_create,\n",
    "            cv2.TrackerDaSiamRPN_create,\n",
    "            #cv2.TrackerMOSSE_create\n",
    "            ]\n",
    "trackerIdx = 0  # 트랙커 생성자 함수 선택 인덱스\n",
    "tracker = None\n",
    "isFirst = True\n",
    "\n",
    "#video_src = 0 # 비디오 파일과 카메라 선택 ---②\n",
    "video_src = \"../data/img/highway.mp4\"\n",
    "cap = cv2.VideoCapture(video_src)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "win_name = 'Tracking APIs'\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Cannot read video file')\n",
    "        break\n",
    "    img_draw = frame.copy()\n",
    "    if tracker is None: # 트랙커 생성 안된 경우\n",
    "        cv2.putText(img_draw, \"Press the Space to set ROI!!\", \\\n",
    "            (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        ok, bbox = tracker.update(frame)   # 새로운 프레임에서 추적 위치 찾기 ---③\n",
    "        (x,y,w,h) = bbox\n",
    "        if ok: # 추적 성공\n",
    "            cv2.rectangle(img_draw, (int(x), int(y)), (int(x + w), int(y + h)), \\\n",
    "                          (0,255,0), 2, 1)\n",
    "        else : # 추적 실패\n",
    "            cv2.putText(img_draw, \"Tracking fail.\", (100,80), \\\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    trackerName = tracker.__class__.__name__\n",
    "    cv2.putText(img_draw, str(trackerIdx) + \":\"+trackerName , (100,20), \\\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(win_name, img_draw)\n",
    "    key = cv2.waitKey(delay) & 0xff\n",
    "    # 스페이스 바 또는 비디오 파일 최초 실행 ---④\n",
    "    if key == ord(' ') or (video_src != 0 and isFirst): \n",
    "        isFirst = False\n",
    "        roi = cv2.selectROI(win_name, frame, False)  # 초기 객체 위치 설정\n",
    "        if roi[2] and roi[3]:         # 위치 설정 값 있는 경우\n",
    "            tracker = trackers[trackerIdx]()    #트랙커 객체 생성 ---⑤\n",
    "            isInit = tracker.init(frame, roi)\n",
    "    elif key in range(48, 56): # 0~7 숫자 입력   ---⑥\n",
    "        trackerIdx = key-48     # 선택한 숫자로 트랙커 인덱스 수정\n",
    "        if bbox is not None:\n",
    "            tracker = trackers[trackerIdx]() # 선택한 숫자의 트랙커 객체 생성 ---⑦\n",
    "            isInit = tracker.init(frame, bbox) # 이전 추적 위치로 추적 위치 초기화\n",
    "    elif key == 27 : \n",
    "        break\n",
    "else:\n",
    "    print( \"Could not open video\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
